{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashaaankk/GradientAscent/blob/main/GradientAscent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gpxpy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import glob\n",
        "import gpxpy\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LOCAL = not 'google.colab' in sys.modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "Mngq1luAl8g2",
        "outputId": "39508712-f216-4b99-b364-a33f4e9681f9"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    !pip install --quiet kaggle kagglehub[pandas-datasets]\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()   # click to select your kaggle.json\n",
        "    if 'kaggle.json' not in uploaded:\n",
        "        raise FileNotFoundError(\"You must upload the kaggle.json you downloaded from Kaggle.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X7oK6Nazs6qJ"
      },
      "outputs": [],
      "source": [
        "if not LOCAL:\n",
        "    import os, shutil\n",
        "    # make sure ~/.kaggle exists\n",
        "    kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "    # move and secure\n",
        "    shutil.move(\"kaggle.json\", os.path.join(kaggle_dir, \"kaggle.json\"))\n",
        "    os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)\n",
        "\n",
        "    # sometimes needed:\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = kaggle_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OqULn93ftgIl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Download complete.\n",
            "Extracting files...\n",
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "if not LOCAL:\n",
        "    import kagglehub\n",
        "    path = kagglehub.dataset_download(\"roccoli/gpx-hike-tracks\")\n",
        "else:\n",
        "    import os\n",
        "    import zipfile\n",
        "    import requests\n",
        "\n",
        "    # Define file and directory paths\n",
        "    data_dir = \"data\"\n",
        "    zip_path = os.path.join(data_dir, \"gpx-hike-tracks.zip\")\n",
        "    download_url = \"https://www.kaggle.com/api/v1/datasets/download/roccoli/gpx-hike-tracks\"\n",
        "\n",
        "    # Ensure the data directory exists\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    # Check if the zip file already exists\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(\"Downloading dataset...\")\n",
        "        response = requests.get(download_url, allow_redirects=True)\n",
        "        if response.status_code == 200:\n",
        "            with open(zip_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(\"Download complete.\")\n",
        "        else:\n",
        "            raise Exception(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "    else:\n",
        "        print(\"Zip file already exists. Skipping download.\")\n",
        "\n",
        "    # Unzip the file\n",
        "    print(\"Extracting files...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    print(\"Extraction complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h2u_1MMRuUSn"
      },
      "outputs": [],
      "source": [
        "# 1. Install gpxpy (to parse .gpx files)\n",
        "import gpxpy\n",
        "import pandas as pd\n",
        "if not LOCAL:\n",
        "\n",
        "    csv_files = glob.glob(os.path.join(path, \"**\", \"*.csv\"), recursive=True)\n",
        "    csv_path = csv_files[0]\n",
        "    print(\"Loading:\", csv_path)\n",
        "\n",
        "else:\n",
        "    csv_path = os.path.join(\"data\", \"gpx-tracks-from-hikr.org.csv\")\n",
        "\n",
        "# Read and inspect\n",
        "df = pd.read_csv(csv_path)\n",
        "# print(\"Shape:\", df.shape)\n",
        "# print(\"Columns:\", df.columns.tolist())\n",
        "# print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mn1XCOEBw6hP"
      },
      "outputs": [],
      "source": [
        "#Pre-processing 1\n",
        "\n",
        "df = df.dropna()\n",
        "# Convert time columns to datetime\n",
        "df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], format=\"%Y-%m-%d %H:%M:%S\" , errors='coerce')\n",
        "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"], format=\"%Y-%m-%d %H:%M:%S\" ,errors='coerce')\n",
        "\n",
        "# Compute total duration in seconds\n",
        "df[\"duration\"] =  df[\"moving_time\"]\n",
        "\n",
        "# Compute break time: duration - moving_time\n",
        "df[\"break_time\"] = (df[\"end_time\"] - df[\"start_time\"]).dt.total_seconds() - df[\"moving_time\"]\n",
        "\n",
        "# Select relevant features\n",
        "selected = df[[\"duration\",\"length_3d\", \"min_elevation\", \"max_elevation\", \"break_time\", \"uphill\", \"downhill\"]]\n",
        "\n",
        "X = selected\n",
        "y = df['difficulty'].str[1].astype(int)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train logistic regression\n",
        "mask = X.notnull().all(axis=1) & y.notnull()\n",
        "X_clean = X_scaled[mask]\n",
        "y_clean = y[mask]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IwQ84hlNyIut"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.59      0.44      0.51       157\n",
            "           2       0.51      0.58      0.54       596\n",
            "           3       0.43      0.70      0.53       693\n",
            "           4       0.26      0.03      0.05       295\n",
            "           5       0.67      0.01      0.03       152\n",
            "           6       0.00      0.00      0.00        56\n",
            "\n",
            "    accuracy                           0.47      1949\n",
            "   macro avg       0.41      0.29      0.28      1949\n",
            "weighted avg       0.45      0.47      0.41      1949\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fsociety/Documents/Uni-Stuttgart/SS2025/AISA/GradientAscent/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/home/fsociety/Documents/Uni-Stuttgart/SS2025/AISA/GradientAscent/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fsociety/Documents/Uni-Stuttgart/SS2025/AISA/GradientAscent/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fsociety/Documents/Uni-Stuttgart/SS2025/AISA/GradientAscent/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THfTKXxXxE4D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
